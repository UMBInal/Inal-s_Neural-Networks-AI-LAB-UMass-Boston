{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f712cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a139d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data\n",
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, header = None)\n",
    "    features = data.iloc[:, :-1].values\n",
    "    labels = data.iloc[:, -1].values - 1  # Shift the class labels to 0-25\n",
    "    return features, labels\n",
    "\n",
    "# Read the data\n",
    "data_url = \"https://raw.githubusercontent.com/UMBInal/data/main/data.csv\"\n",
    "x, y = read_data(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff659dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01176471, 0.01176471, 0.97647059, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e038d713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270ff628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72ae9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.08, 0.76, 0.12, 0.  , 0.  , 0.04, 0.  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b66f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25669"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb72a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25669, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03902b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25669,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a64a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4f9806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25669, 10, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b64a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the input shape and number of classes\n",
    "input_shape = (x_train.shape[1], 1)\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a6be14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc0732f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5dc31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder function\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed-forward network\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf58f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Decoder function\n",
    "def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(res, enc_outputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = x + res\n",
    "\n",
    "    # Feed-forward network\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(inputs.shape[-1], activation=\"softmax\")(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4b6708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Encoder\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = keras.Input(shape=input_shape)\n",
    "    dec = decoder_input\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        dec = transformer_decoder(dec, x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    dec = layers.Flatten()(dec)\n",
    "    x = layers.Concatenate()([x, dec])\n",
    "\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model([inputs, decoder_input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abce5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "head_size = 2\n",
    "num_heads = 8\n",
    "ff_dim = 64\n",
    "num_transformer_blocks = 6\n",
    "mlp_units = [64]\n",
    "dropout = 0.1\n",
    "mlp_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6dc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "281/281 [==============================] - 24s 33ms/step - loss: 2.0827 - accuracy: 0.4392 - val_loss: 1.6181 - val_accuracy: 0.5234\n",
      "Epoch 2/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.5238 - accuracy: 0.5348 - val_loss: 1.4175 - val_accuracy: 0.5612\n",
      "Epoch 3/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.4039 - accuracy: 0.5549 - val_loss: 1.3401 - val_accuracy: 0.5777\n",
      "Epoch 4/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.3459 - accuracy: 0.5689 - val_loss: 1.2955 - val_accuracy: 0.5884\n",
      "Epoch 5/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.3098 - accuracy: 0.5743 - val_loss: 1.2663 - val_accuracy: 0.6020\n",
      "Epoch 6/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.2882 - accuracy: 0.5774 - val_loss: 1.2425 - val_accuracy: 0.6017\n",
      "Epoch 7/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.2658 - accuracy: 0.5874 - val_loss: 1.2264 - val_accuracy: 0.5975\n",
      "Epoch 8/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.2481 - accuracy: 0.5904 - val_loss: 1.2055 - val_accuracy: 0.6136\n",
      "Epoch 9/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.2324 - accuracy: 0.5955 - val_loss: 1.1916 - val_accuracy: 0.6151\n",
      "Epoch 10/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.2198 - accuracy: 0.5961 - val_loss: 1.1790 - val_accuracy: 0.6146\n",
      "Epoch 11/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.2080 - accuracy: 0.6018 - val_loss: 1.1646 - val_accuracy: 0.6160\n",
      "Epoch 12/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.1918 - accuracy: 0.6030 - val_loss: 1.1554 - val_accuracy: 0.6198\n",
      "Epoch 13/200\n",
      " 95/281 [=========>....................] - ETA: 4s - loss: 1.1769 - accuracy: 0.6104"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([x_train, x_train], y_train, batch_size=64, epochs=200, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd825c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([x_test, x_test], y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
