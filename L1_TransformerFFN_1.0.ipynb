{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f712cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a139d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the data\n",
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, header = None)\n",
    "    features = data.iloc[:, :-1].values\n",
    "    labels = data.iloc[:, -1].values - 1  # Shift the class labels to 0-25\n",
    "    return features, labels\n",
    "\n",
    "# Read the data\n",
    "data_url = \"https://raw.githubusercontent.com/UMBInal/data/main/data.csv\"\n",
    "x, y = read_data(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e843e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01176471, 0.01176471, 0.97647059, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7870328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270ff628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51d40ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.08, 0.76, 0.12, 0.  , 0.  , 0.04, 0.  ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b24842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25669"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268d94d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25669, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75093584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25669,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a64a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec2799e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25669, 10, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b64a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the input shape and number of classes\n",
    "input_shape = (x_train.shape[1], 1)\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c488c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f82b8540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5dc31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Encoder function\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed-forward network\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(inputs.shape[-1], activation = 'softmax')(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf58f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Decoder function\n",
    "def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(res, enc_outputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = x + res\n",
    "\n",
    "    # Feed-forward network\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(inputs.shape[-1], activation=\"softmax\")(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4b6708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Encoder\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = keras.Input(shape=input_shape)\n",
    "    dec = decoder_input\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        dec = transformer_decoder(dec, x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    dec = layers.Flatten()(dec)\n",
    "    x = layers.Concatenate()([x, dec])\n",
    "\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model([inputs, decoder_input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abce5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "head_size = 2\n",
    "num_heads = 8\n",
    "ff_dim = 64\n",
    "num_transformer_blocks = 6\n",
    "mlp_units = [64]\n",
    "dropout = 0.1\n",
    "mlp_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6dc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dd1532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "281/281 [==============================] - 24s 33ms/step - loss: 2.0827 - accuracy: 0.4392 - val_loss: 1.6181 - val_accuracy: 0.5234\n",
      "Epoch 2/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.5238 - accuracy: 0.5348 - val_loss: 1.4175 - val_accuracy: 0.5612\n",
      "Epoch 3/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.4039 - accuracy: 0.5549 - val_loss: 1.3401 - val_accuracy: 0.5777\n",
      "Epoch 4/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.3459 - accuracy: 0.5689 - val_loss: 1.2955 - val_accuracy: 0.5884\n",
      "Epoch 5/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.3098 - accuracy: 0.5743 - val_loss: 1.2663 - val_accuracy: 0.6020\n",
      "Epoch 6/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.2882 - accuracy: 0.5774 - val_loss: 1.2425 - val_accuracy: 0.6017\n",
      "Epoch 7/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.2658 - accuracy: 0.5874 - val_loss: 1.2264 - val_accuracy: 0.5975\n",
      "Epoch 8/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.2481 - accuracy: 0.5904 - val_loss: 1.2055 - val_accuracy: 0.6136\n",
      "Epoch 9/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.2324 - accuracy: 0.5955 - val_loss: 1.1916 - val_accuracy: 0.6151\n",
      "Epoch 10/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.2198 - accuracy: 0.5961 - val_loss: 1.1790 - val_accuracy: 0.6146\n",
      "Epoch 11/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.2080 - accuracy: 0.6018 - val_loss: 1.1646 - val_accuracy: 0.6160\n",
      "Epoch 12/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.1918 - accuracy: 0.6030 - val_loss: 1.1554 - val_accuracy: 0.6198\n",
      "Epoch 13/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.1801 - accuracy: 0.6062 - val_loss: 1.1490 - val_accuracy: 0.6126\n",
      "Epoch 14/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.1728 - accuracy: 0.6087 - val_loss: 1.1374 - val_accuracy: 0.6265\n",
      "Epoch 15/200\n",
      "281/281 [==============================] - 8s 28ms/step - loss: 1.1649 - accuracy: 0.6135 - val_loss: 1.1331 - val_accuracy: 0.6172\n",
      "Epoch 16/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.1564 - accuracy: 0.6132 - val_loss: 1.1156 - val_accuracy: 0.6242\n",
      "Epoch 17/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.1476 - accuracy: 0.6136 - val_loss: 1.1154 - val_accuracy: 0.6260\n",
      "Epoch 18/200\n",
      "281/281 [==============================] - 9s 33ms/step - loss: 1.1395 - accuracy: 0.6206 - val_loss: 1.1050 - val_accuracy: 0.6356\n",
      "Epoch 19/200\n",
      "281/281 [==============================] - 9s 31ms/step - loss: 1.1330 - accuracy: 0.6204 - val_loss: 1.1012 - val_accuracy: 0.6287\n",
      "Epoch 20/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.1272 - accuracy: 0.6208 - val_loss: 1.0954 - val_accuracy: 0.6307\n",
      "Epoch 21/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.1190 - accuracy: 0.6234 - val_loss: 1.0876 - val_accuracy: 0.6341\n",
      "Epoch 22/200\n",
      "281/281 [==============================] - 9s 31ms/step - loss: 1.1108 - accuracy: 0.6235 - val_loss: 1.0873 - val_accuracy: 0.6355\n",
      "Epoch 23/200\n",
      "281/281 [==============================] - 9s 30ms/step - loss: 1.1073 - accuracy: 0.6297 - val_loss: 1.0748 - val_accuracy: 0.6371\n",
      "Epoch 24/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.1022 - accuracy: 0.6285 - val_loss: 1.0674 - val_accuracy: 0.6420\n",
      "Epoch 25/200\n",
      "281/281 [==============================] - 9s 31ms/step - loss: 1.0973 - accuracy: 0.6301 - val_loss: 1.0681 - val_accuracy: 0.6374\n",
      "Epoch 26/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0912 - accuracy: 0.6323 - val_loss: 1.0633 - val_accuracy: 0.6386\n",
      "Epoch 27/200\n",
      "281/281 [==============================] - 9s 31ms/step - loss: 1.0851 - accuracy: 0.6323 - val_loss: 1.0566 - val_accuracy: 0.6382\n",
      "Epoch 28/200\n",
      "281/281 [==============================] - 9s 32ms/step - loss: 1.0806 - accuracy: 0.6374 - val_loss: 1.0435 - val_accuracy: 0.6455\n",
      "Epoch 29/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0785 - accuracy: 0.6350 - val_loss: 1.0432 - val_accuracy: 0.6420\n",
      "Epoch 30/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0709 - accuracy: 0.6385 - val_loss: 1.0473 - val_accuracy: 0.6374\n",
      "Epoch 31/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0683 - accuracy: 0.6339 - val_loss: 1.0356 - val_accuracy: 0.6415\n",
      "Epoch 32/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0615 - accuracy: 0.6380 - val_loss: 1.0328 - val_accuracy: 0.6442\n",
      "Epoch 33/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0579 - accuracy: 0.6381 - val_loss: 1.0240 - val_accuracy: 0.6438\n",
      "Epoch 34/200\n",
      "281/281 [==============================] - 9s 32ms/step - loss: 1.0563 - accuracy: 0.6400 - val_loss: 1.0260 - val_accuracy: 0.6498\n",
      "Epoch 35/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0503 - accuracy: 0.6430 - val_loss: 1.0174 - val_accuracy: 0.6516\n",
      "Epoch 36/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0467 - accuracy: 0.6426 - val_loss: 1.0162 - val_accuracy: 0.6499\n",
      "Epoch 37/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0455 - accuracy: 0.6402 - val_loss: 1.0089 - val_accuracy: 0.6529\n",
      "Epoch 38/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0427 - accuracy: 0.6438 - val_loss: 1.0070 - val_accuracy: 0.6446\n",
      "Epoch 39/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0369 - accuracy: 0.6431 - val_loss: 1.0029 - val_accuracy: 0.6510\n",
      "Epoch 40/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0385 - accuracy: 0.6459 - val_loss: 1.0002 - val_accuracy: 0.6525\n",
      "Epoch 41/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0350 - accuracy: 0.6454 - val_loss: 0.9983 - val_accuracy: 0.6523\n",
      "Epoch 42/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0290 - accuracy: 0.6467 - val_loss: 0.9985 - val_accuracy: 0.6585\n",
      "Epoch 43/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0272 - accuracy: 0.6479 - val_loss: 1.0012 - val_accuracy: 0.6550\n",
      "Epoch 44/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0247 - accuracy: 0.6435 - val_loss: 0.9893 - val_accuracy: 0.6612\n",
      "Epoch 45/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0201 - accuracy: 0.6489 - val_loss: 0.9826 - val_accuracy: 0.6574\n",
      "Epoch 46/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0158 - accuracy: 0.6492 - val_loss: 0.9794 - val_accuracy: 0.6646\n",
      "Epoch 47/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0169 - accuracy: 0.6483 - val_loss: 0.9810 - val_accuracy: 0.6628\n",
      "Epoch 48/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0106 - accuracy: 0.6505 - val_loss: 0.9784 - val_accuracy: 0.6625\n",
      "Epoch 49/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0131 - accuracy: 0.6509 - val_loss: 0.9829 - val_accuracy: 0.6559\n",
      "Epoch 50/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0069 - accuracy: 0.6520 - val_loss: 0.9713 - val_accuracy: 0.6573\n",
      "Epoch 51/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 1.0009 - accuracy: 0.6519 - val_loss: 0.9707 - val_accuracy: 0.6660\n",
      "Epoch 52/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0029 - accuracy: 0.6513 - val_loss: 0.9639 - val_accuracy: 0.6700\n",
      "Epoch 53/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 1.0017 - accuracy: 0.6520 - val_loss: 0.9653 - val_accuracy: 0.6589\n",
      "Epoch 54/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9958 - accuracy: 0.6547 - val_loss: 0.9626 - val_accuracy: 0.6607\n",
      "Epoch 55/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9954 - accuracy: 0.6525 - val_loss: 0.9546 - val_accuracy: 0.6628\n",
      "Epoch 56/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9925 - accuracy: 0.6573 - val_loss: 0.9521 - val_accuracy: 0.6628\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9899 - accuracy: 0.6592 - val_loss: 0.9560 - val_accuracy: 0.6651\n",
      "Epoch 58/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9890 - accuracy: 0.6571 - val_loss: 0.9492 - val_accuracy: 0.6620\n",
      "Epoch 59/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9852 - accuracy: 0.6598 - val_loss: 0.9462 - val_accuracy: 0.6695\n",
      "Epoch 60/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9827 - accuracy: 0.6593 - val_loss: 0.9428 - val_accuracy: 0.6655\n",
      "Epoch 61/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9810 - accuracy: 0.6597 - val_loss: 0.9460 - val_accuracy: 0.6715\n",
      "Epoch 62/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9790 - accuracy: 0.6600 - val_loss: 0.9386 - val_accuracy: 0.6780\n",
      "Epoch 63/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9730 - accuracy: 0.6643 - val_loss: 0.9358 - val_accuracy: 0.6769\n",
      "Epoch 64/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9733 - accuracy: 0.6626 - val_loss: 0.9368 - val_accuracy: 0.6710\n",
      "Epoch 65/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9714 - accuracy: 0.6633 - val_loss: 0.9304 - val_accuracy: 0.6694\n",
      "Epoch 66/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9684 - accuracy: 0.6633 - val_loss: 0.9292 - val_accuracy: 0.6721\n",
      "Epoch 67/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9659 - accuracy: 0.6655 - val_loss: 0.9289 - val_accuracy: 0.6664\n",
      "Epoch 68/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9656 - accuracy: 0.6685 - val_loss: 0.9256 - val_accuracy: 0.6733\n",
      "Epoch 69/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9590 - accuracy: 0.6666 - val_loss: 0.9240 - val_accuracy: 0.6743\n",
      "Epoch 70/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9588 - accuracy: 0.6672 - val_loss: 0.9204 - val_accuracy: 0.6784\n",
      "Epoch 71/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9561 - accuracy: 0.6684 - val_loss: 0.9170 - val_accuracy: 0.6807\n",
      "Epoch 72/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9549 - accuracy: 0.6684 - val_loss: 0.9142 - val_accuracy: 0.6773\n",
      "Epoch 73/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9532 - accuracy: 0.6680 - val_loss: 0.9165 - val_accuracy: 0.6819\n",
      "Epoch 74/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9523 - accuracy: 0.6710 - val_loss: 0.9127 - val_accuracy: 0.6768\n",
      "Epoch 75/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9545 - accuracy: 0.6711 - val_loss: 0.9126 - val_accuracy: 0.6794\n",
      "Epoch 76/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9498 - accuracy: 0.6716 - val_loss: 0.9071 - val_accuracy: 0.6843\n",
      "Epoch 77/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9419 - accuracy: 0.6706 - val_loss: 0.9054 - val_accuracy: 0.6864\n",
      "Epoch 78/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9424 - accuracy: 0.6727 - val_loss: 0.9043 - val_accuracy: 0.6868\n",
      "Epoch 79/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9419 - accuracy: 0.6703 - val_loss: 0.9021 - val_accuracy: 0.6771\n",
      "Epoch 80/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9405 - accuracy: 0.6716 - val_loss: 0.9026 - val_accuracy: 0.6874\n",
      "Epoch 81/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9398 - accuracy: 0.6725 - val_loss: 0.8955 - val_accuracy: 0.6891\n",
      "Epoch 82/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9388 - accuracy: 0.6741 - val_loss: 0.8939 - val_accuracy: 0.6893\n",
      "Epoch 83/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9363 - accuracy: 0.6724 - val_loss: 0.8937 - val_accuracy: 0.6843\n",
      "Epoch 84/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9355 - accuracy: 0.6732 - val_loss: 0.8922 - val_accuracy: 0.6842\n",
      "Epoch 85/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9330 - accuracy: 0.6742 - val_loss: 0.8962 - val_accuracy: 0.6848\n",
      "Epoch 86/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9315 - accuracy: 0.6758 - val_loss: 0.8874 - val_accuracy: 0.6878\n",
      "Epoch 87/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9319 - accuracy: 0.6742 - val_loss: 0.8880 - val_accuracy: 0.6906\n",
      "Epoch 88/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9281 - accuracy: 0.6761 - val_loss: 0.8908 - val_accuracy: 0.6845\n",
      "Epoch 89/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9272 - accuracy: 0.6786 - val_loss: 0.8831 - val_accuracy: 0.6886\n",
      "Epoch 90/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9261 - accuracy: 0.6745 - val_loss: 0.8847 - val_accuracy: 0.6894\n",
      "Epoch 91/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9236 - accuracy: 0.6803 - val_loss: 0.8784 - val_accuracy: 0.6971\n",
      "Epoch 92/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9188 - accuracy: 0.6801 - val_loss: 0.8817 - val_accuracy: 0.6885\n",
      "Epoch 93/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9202 - accuracy: 0.6784 - val_loss: 0.8794 - val_accuracy: 0.6897\n",
      "Epoch 94/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9184 - accuracy: 0.6772 - val_loss: 0.8841 - val_accuracy: 0.6885\n",
      "Epoch 95/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9161 - accuracy: 0.6789 - val_loss: 0.8756 - val_accuracy: 0.6919\n",
      "Epoch 96/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9204 - accuracy: 0.6774 - val_loss: 0.8723 - val_accuracy: 0.6967\n",
      "Epoch 97/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9140 - accuracy: 0.6817 - val_loss: 0.8720 - val_accuracy: 0.6900\n",
      "Epoch 98/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9122 - accuracy: 0.6764 - val_loss: 0.8734 - val_accuracy: 0.6917\n",
      "Epoch 99/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9119 - accuracy: 0.6794 - val_loss: 0.8720 - val_accuracy: 0.6956\n",
      "Epoch 100/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9101 - accuracy: 0.6827 - val_loss: 0.8782 - val_accuracy: 0.6895\n",
      "Epoch 101/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9103 - accuracy: 0.6795 - val_loss: 0.8648 - val_accuracy: 0.6900\n",
      "Epoch 102/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9079 - accuracy: 0.6829 - val_loss: 0.8637 - val_accuracy: 0.6907\n",
      "Epoch 103/200\n",
      "281/281 [==============================] - 9s 30ms/step - loss: 0.9060 - accuracy: 0.6820 - val_loss: 0.8609 - val_accuracy: 0.6935\n",
      "Epoch 104/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.9029 - accuracy: 0.6839 - val_loss: 0.8632 - val_accuracy: 0.7008\n",
      "Epoch 105/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9020 - accuracy: 0.6824 - val_loss: 0.8584 - val_accuracy: 0.6973\n",
      "Epoch 106/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9040 - accuracy: 0.6815 - val_loss: 0.8586 - val_accuracy: 0.6907\n",
      "Epoch 107/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.9018 - accuracy: 0.6814 - val_loss: 0.8567 - val_accuracy: 0.6972\n",
      "Epoch 108/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8975 - accuracy: 0.6851 - val_loss: 0.8525 - val_accuracy: 0.7008\n",
      "Epoch 109/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8949 - accuracy: 0.6810 - val_loss: 0.8523 - val_accuracy: 0.7016\n",
      "Epoch 110/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8954 - accuracy: 0.6844 - val_loss: 0.8512 - val_accuracy: 0.6973\n",
      "Epoch 111/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8941 - accuracy: 0.6847 - val_loss: 0.8571 - val_accuracy: 0.6980\n",
      "Epoch 112/200\n",
      "281/281 [==============================] - 9s 30ms/step - loss: 0.8957 - accuracy: 0.6817 - val_loss: 0.8559 - val_accuracy: 0.6909\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8920 - accuracy: 0.6844 - val_loss: 0.8508 - val_accuracy: 0.6990\n",
      "Epoch 114/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8947 - accuracy: 0.6819 - val_loss: 0.8481 - val_accuracy: 0.7013\n",
      "Epoch 115/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8885 - accuracy: 0.6851 - val_loss: 0.8484 - val_accuracy: 0.7056\n",
      "Epoch 116/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8897 - accuracy: 0.6863 - val_loss: 0.8439 - val_accuracy: 0.7002\n",
      "Epoch 117/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8917 - accuracy: 0.6832 - val_loss: 0.8448 - val_accuracy: 0.7042\n",
      "Epoch 118/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8859 - accuracy: 0.6886 - val_loss: 0.8437 - val_accuracy: 0.6985\n",
      "Epoch 119/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8862 - accuracy: 0.6851 - val_loss: 0.8397 - val_accuracy: 0.7039\n",
      "Epoch 120/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8843 - accuracy: 0.6889 - val_loss: 0.8458 - val_accuracy: 0.6906\n",
      "Epoch 121/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8862 - accuracy: 0.6839 - val_loss: 0.8399 - val_accuracy: 0.6893\n",
      "Epoch 122/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8827 - accuracy: 0.6851 - val_loss: 0.8371 - val_accuracy: 0.6994\n",
      "Epoch 123/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8872 - accuracy: 0.6843 - val_loss: 0.8365 - val_accuracy: 0.7056\n",
      "Epoch 124/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8833 - accuracy: 0.6850 - val_loss: 0.8354 - val_accuracy: 0.7043\n",
      "Epoch 125/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8789 - accuracy: 0.6888 - val_loss: 0.8362 - val_accuracy: 0.7030\n",
      "Epoch 126/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8824 - accuracy: 0.6835 - val_loss: 0.8360 - val_accuracy: 0.7012\n",
      "Epoch 127/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8784 - accuracy: 0.6876 - val_loss: 0.8356 - val_accuracy: 0.6954\n",
      "Epoch 128/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8774 - accuracy: 0.6886 - val_loss: 0.8282 - val_accuracy: 0.7054\n",
      "Epoch 129/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8770 - accuracy: 0.6923 - val_loss: 0.8297 - val_accuracy: 0.6994\n",
      "Epoch 130/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8764 - accuracy: 0.6892 - val_loss: 0.8294 - val_accuracy: 0.7048\n",
      "Epoch 131/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8789 - accuracy: 0.6845 - val_loss: 0.8278 - val_accuracy: 0.7046\n",
      "Epoch 132/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8738 - accuracy: 0.6887 - val_loss: 0.8284 - val_accuracy: 0.7020\n",
      "Epoch 133/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8757 - accuracy: 0.6872 - val_loss: 0.8358 - val_accuracy: 0.7006\n",
      "Epoch 134/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8715 - accuracy: 0.6861 - val_loss: 0.8254 - val_accuracy: 0.7003\n",
      "Epoch 135/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8716 - accuracy: 0.6912 - val_loss: 0.8194 - val_accuracy: 0.6985\n",
      "Epoch 136/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8697 - accuracy: 0.6892 - val_loss: 0.8232 - val_accuracy: 0.7037\n",
      "Epoch 137/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8673 - accuracy: 0.6922 - val_loss: 0.8267 - val_accuracy: 0.6978\n",
      "Epoch 138/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8739 - accuracy: 0.6887 - val_loss: 0.8188 - val_accuracy: 0.7035\n",
      "Epoch 139/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8658 - accuracy: 0.6893 - val_loss: 0.8188 - val_accuracy: 0.7039\n",
      "Epoch 140/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8664 - accuracy: 0.6925 - val_loss: 0.8208 - val_accuracy: 0.7100\n",
      "Epoch 141/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8668 - accuracy: 0.6908 - val_loss: 0.8202 - val_accuracy: 0.7042\n",
      "Epoch 142/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8665 - accuracy: 0.6917 - val_loss: 0.8175 - val_accuracy: 0.7061\n",
      "Epoch 143/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8654 - accuracy: 0.6885 - val_loss: 0.8185 - val_accuracy: 0.7037\n",
      "Epoch 144/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8660 - accuracy: 0.6945 - val_loss: 0.8140 - val_accuracy: 0.7080\n",
      "Epoch 145/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8616 - accuracy: 0.6894 - val_loss: 0.8177 - val_accuracy: 0.7074\n",
      "Epoch 146/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8611 - accuracy: 0.6920 - val_loss: 0.8131 - val_accuracy: 0.7080\n",
      "Epoch 147/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8604 - accuracy: 0.6921 - val_loss: 0.8149 - val_accuracy: 0.7064\n",
      "Epoch 148/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8613 - accuracy: 0.6928 - val_loss: 0.8109 - val_accuracy: 0.7090\n",
      "Epoch 149/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8571 - accuracy: 0.6961 - val_loss: 0.8076 - val_accuracy: 0.7103\n",
      "Epoch 150/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8607 - accuracy: 0.6900 - val_loss: 0.8089 - val_accuracy: 0.7091\n",
      "Epoch 151/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8556 - accuracy: 0.6955 - val_loss: 0.8134 - val_accuracy: 0.7106\n",
      "Epoch 152/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8603 - accuracy: 0.6916 - val_loss: 0.8137 - val_accuracy: 0.7067\n",
      "Epoch 153/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8581 - accuracy: 0.6934 - val_loss: 0.8065 - val_accuracy: 0.7095\n",
      "Epoch 154/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8546 - accuracy: 0.6934 - val_loss: 0.8071 - val_accuracy: 0.7095\n",
      "Epoch 155/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8586 - accuracy: 0.6913 - val_loss: 0.8044 - val_accuracy: 0.7165\n",
      "Epoch 156/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8574 - accuracy: 0.6909 - val_loss: 0.8097 - val_accuracy: 0.7081\n",
      "Epoch 157/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8556 - accuracy: 0.6940 - val_loss: 0.8062 - val_accuracy: 0.7064\n",
      "Epoch 158/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8501 - accuracy: 0.6948 - val_loss: 0.8007 - val_accuracy: 0.7113\n",
      "Epoch 159/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8495 - accuracy: 0.6961 - val_loss: 0.8036 - val_accuracy: 0.7117\n",
      "Epoch 160/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8538 - accuracy: 0.6964 - val_loss: 0.8036 - val_accuracy: 0.7085\n",
      "Epoch 161/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8481 - accuracy: 0.6961 - val_loss: 0.8013 - val_accuracy: 0.7041\n",
      "Epoch 162/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8511 - accuracy: 0.6946 - val_loss: 0.7978 - val_accuracy: 0.7122\n",
      "Epoch 163/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8454 - accuracy: 0.6968 - val_loss: 0.8008 - val_accuracy: 0.7090\n",
      "Epoch 164/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8470 - accuracy: 0.6963 - val_loss: 0.7960 - val_accuracy: 0.7135\n",
      "Epoch 165/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8456 - accuracy: 0.6983 - val_loss: 0.7974 - val_accuracy: 0.7242\n",
      "Epoch 166/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8465 - accuracy: 0.6966 - val_loss: 0.7974 - val_accuracy: 0.7173\n",
      "Epoch 167/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8462 - accuracy: 0.6958 - val_loss: 0.7937 - val_accuracy: 0.7145\n",
      "Epoch 168/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8418 - accuracy: 0.6957 - val_loss: 0.7976 - val_accuracy: 0.7139\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8434 - accuracy: 0.6966 - val_loss: 0.7895 - val_accuracy: 0.7137\n",
      "Epoch 170/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8393 - accuracy: 0.6971 - val_loss: 0.7886 - val_accuracy: 0.7154\n",
      "Epoch 171/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8404 - accuracy: 0.7000 - val_loss: 0.7899 - val_accuracy: 0.7152\n",
      "Epoch 172/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8410 - accuracy: 0.6992 - val_loss: 0.7896 - val_accuracy: 0.7181\n",
      "Epoch 173/200\n",
      "281/281 [==============================] - 8s 30ms/step - loss: 0.8417 - accuracy: 0.6992 - val_loss: 0.7887 - val_accuracy: 0.7122\n",
      "Epoch 174/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8365 - accuracy: 0.7001 - val_loss: 0.7923 - val_accuracy: 0.7150\n",
      "Epoch 175/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8363 - accuracy: 0.7004 - val_loss: 0.7879 - val_accuracy: 0.7219\n",
      "Epoch 176/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8350 - accuracy: 0.7016 - val_loss: 0.7893 - val_accuracy: 0.7146\n",
      "Epoch 177/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8334 - accuracy: 0.6992 - val_loss: 0.7848 - val_accuracy: 0.7186\n",
      "Epoch 178/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8377 - accuracy: 0.6987 - val_loss: 0.7871 - val_accuracy: 0.7152\n",
      "Epoch 179/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8347 - accuracy: 0.6994 - val_loss: 0.7891 - val_accuracy: 0.7104\n",
      "Epoch 180/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8322 - accuracy: 0.6988 - val_loss: 0.7839 - val_accuracy: 0.7115\n",
      "Epoch 181/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8334 - accuracy: 0.7016 - val_loss: 0.7831 - val_accuracy: 0.7198\n",
      "Epoch 182/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8289 - accuracy: 0.6995 - val_loss: 0.7788 - val_accuracy: 0.7232\n",
      "Epoch 183/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8309 - accuracy: 0.7008 - val_loss: 0.7776 - val_accuracy: 0.7254\n",
      "Epoch 184/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8279 - accuracy: 0.7004 - val_loss: 0.7816 - val_accuracy: 0.7274\n",
      "Epoch 185/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8292 - accuracy: 0.7026 - val_loss: 0.7760 - val_accuracy: 0.7226\n",
      "Epoch 186/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8336 - accuracy: 0.6972 - val_loss: 0.7797 - val_accuracy: 0.7176\n",
      "Epoch 187/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8310 - accuracy: 0.7024 - val_loss: 0.7765 - val_accuracy: 0.7199\n",
      "Epoch 188/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8275 - accuracy: 0.7040 - val_loss: 0.7780 - val_accuracy: 0.7247\n",
      "Epoch 189/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8275 - accuracy: 0.6982 - val_loss: 0.7786 - val_accuracy: 0.7180\n",
      "Epoch 190/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8266 - accuracy: 0.7021 - val_loss: 0.7756 - val_accuracy: 0.7198\n",
      "Epoch 191/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8232 - accuracy: 0.7036 - val_loss: 0.7792 - val_accuracy: 0.7220\n",
      "Epoch 192/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8240 - accuracy: 0.7019 - val_loss: 0.7739 - val_accuracy: 0.7170\n",
      "Epoch 193/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8247 - accuracy: 0.7010 - val_loss: 0.7764 - val_accuracy: 0.7137\n",
      "Epoch 194/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8254 - accuracy: 0.7015 - val_loss: 0.7680 - val_accuracy: 0.7224\n",
      "Epoch 195/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8231 - accuracy: 0.7052 - val_loss: 0.7703 - val_accuracy: 0.7241\n",
      "Epoch 196/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8228 - accuracy: 0.7043 - val_loss: 0.7745 - val_accuracy: 0.7216\n",
      "Epoch 197/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8262 - accuracy: 0.7043 - val_loss: 0.7674 - val_accuracy: 0.7230\n",
      "Epoch 198/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8188 - accuracy: 0.7051 - val_loss: 0.7727 - val_accuracy: 0.7191\n",
      "Epoch 199/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8222 - accuracy: 0.7033 - val_loss: 0.7682 - val_accuracy: 0.7222\n",
      "Epoch 200/200\n",
      "281/281 [==============================] - 8s 29ms/step - loss: 0.8160 - accuracy: 0.7053 - val_loss: 0.7675 - val_accuracy: 0.7224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173946b4f70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([x_train, x_train], y_train, batch_size=64, epochs=200, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fd825c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/344 [==============================] - 2s 5ms/step - loss: 0.7708 - accuracy: 0.7192\n",
      "Test loss: 0.770835816860199, Test accuracy: 0.7192073464393616\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([x_test, x_test], y_test)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
